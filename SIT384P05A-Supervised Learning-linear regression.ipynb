{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 5: Supervised Learning \n",
    "\n",
    "\n",
    "Upon completion of this session you should be able to:\n",
    "- understand data dependency, linear regression and distances.\n",
    "- be able to apply linear regression in Python.\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- Jupyter source file can be downloaded from https://github.com/gaoshangdeakin/SIT384-Jupyter\n",
    "- If you found any issue/bug for this document, please submit an issue at [https://github.com/gaoshangdeakin/SIT384/issues](https://github.com/gaoshangdeakin/SIT384/issues)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "This practical session will demonstrate different coefficient and linear regression.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "### Machine Learning \n",
    "\n",
    "### Part 1 Data Dependency\n",
    "\n",
    "1.1 [Pearson's-r Correlation coefficient](#pearson)\n",
    "\n",
    "1.2 [Spearman's rank coefficient](#spearman)\n",
    "\n",
    "\n",
    "### Part 2 Linear Regression\n",
    "\n",
    "2.1 [Multiple Linear Regression](#mlr)\n",
    "\n",
    "2.2 [Regression for Median House Price](#rmhp)\n",
    "\n",
    "### Part 3 Distances\n",
    "\n",
    "3.1 [Euclidean Distance](#euclidean)\n",
    "\n",
    "3.2 [Cosine Distance](#cosine)\n",
    "\n",
    "3.3 [Term-by-Document Matrix](#t2d)\n",
    "\n",
    "\n",
    "## Tasks\n",
    "\n",
    "## Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Machine Learning</span>\n",
    "\n",
    "<a id = \"machinelearning\"></a>\n",
    "\n",
    "Machine learning (ML) is \"Machines imitating and adapting human like behavior\". In other words, we try to teach machines to “Learn from Experience”.\n",
    "\n",
    "Machine learning algorithms use computational methods to “learn” information directly from data without relying on a predetermined equation as a model. The algorithms adaptively improve their performance as the number of samples available for learning increases. The ML-Algorithms find natural patterns within the data, get insights and predict the unknown for better decisions.\n",
    "\n",
    "There are basically two types of ML Techniques:\n",
    "\n",
    "   1. Supervised Learning\n",
    "   2. Unsupervised Learning\n",
    "\n",
    "###Supervised Learning:\n",
    "\n",
    "Finds patterns (and develops predictive models) using both, input data and output data. All Supervised Learning techniques area form of either Classification or Regression.\n",
    "\n",
    "* Classification: used for predicting discrete responses.E.g. Whether India will WIN or LOSE a Cricket match? Whether an email is SPAM or GENUINE? WIN, LOSE, SPAM, GENUINE are the predefined classes. And output has to fall among these depending on the input.\n",
    "* Regression: used for predicting continuous responses.E.g. Trend in stock market prices, Weather forecast, etc.\n",
    "\n",
    "###Unsupervised Learning:\n",
    "\n",
    "Finds patterns based only on input data. This technique is useful when you’re not quite sure what to look for. Often used for exploratory Analysis of raw data. Most Unsupervised Learning techniques are a form of Cluster Analysis.\n",
    "\n",
    "* Cluster Analysis: you group data items that have some measure of similarity based on characteristic values. At the end what you will have is a set of different groups (Let’s assume A — Z such groups). A Data Item(d1) in one group(A) is very much similar to other Data Items(d2 — dx) in the same group(A), but d1 is significantly different from Data Items belonging to different groups (B — Z).\n",
    "\n",
    "SciPy and Scikit-Learn will be used in machine learning. For a quick review, go [.html version](practical5-review.html) or [.ipynb version](https://github.com/gaoshangdeakin/SIT384-Jupyter/practical5-review.ipynb).  \n",
    "\n",
    "Before introducing regression, let's talk about data dependency first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#0b486b\">1. Data Dependency</span>\n",
    "\n",
    "<a id = \"pearson\"></a>\n",
    "\n",
    "\n",
    "### <span style=\"color:#0b486b\">1.1 Pearson's-r Correlation coefficient</span>\n",
    "\n",
    "The Pearson product-moment correlation coefficient is a measure of the strength of the linear relationship between two variables. The symbol for Pearson's correlation is \"ρ\" when it is measured in the population and \"r\" when it is measured in a sample. More detail can be found [statistics.laerd.com](https://statistics.laerd.com/statistical-guides/pearson-correlation-coefficient-statistical-guide.php) or [wikipedia.org](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).\n",
    "\n",
    "We assume $X=\\left\\{ X_{1},\\ldots,X_{n}\\right\\}$ \n",
    "and $Y=\\left\\{ Y_{1},\\ldots,Y_{n}\\right\\}$. Then Pearson-r correlation coefficient is defined as \n",
    "\n",
    "$$ \\rho(X,Y) = \\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y} =  \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum_{i=1}^n(X_i-\\bar{X})^2} \\sqrt{\\sum_{i=1}^n(Y_i-\\bar{Y})^2}} $$\n",
    "\n",
    "Use the car data and find the Pearson's-r correlation coefficient between car weights and fuel consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to use wget if you've retrieved file from clouddeakin.\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "link_to_data = 'https://raw.githubusercontent.com/gaoshangdeakin/SIT384/master/Auto.csv'\n",
    "DataSet = wget.download(link_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miles = data['miles']\n",
    "weights = data['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"miles[:10]:\", miles[:10])\n",
    "print(\"weights[:10]:\", weights[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_r = np.cov(miles, weights)[0, 1] / (miles.std() * weights.std())\n",
    "print(\"pearson_r:\", pearson_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(miles,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horse = data['Horse power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(weights,horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig, ax = plt.subplots(figsize=(7, 5), dpi=100)\n",
    "ax.scatter(weights,miles, alpha=0.6, edgecolor='none', s=100)\n",
    "ax.set_xlabel('Car Weight (tons)')\n",
    "ax.set_ylabel('Miles Per Gallon')\n",
    "\n",
    "line_coef = np.polyfit(weights, miles, 1)\n",
    "xx = np.arange(1, 5, 0.1)\n",
    "yy = line_coef[0]*xx + line_coef[1]\n",
    "\n",
    "ax.plot(xx, yy, 'r', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: \n",
    "\n",
    "1. Find the Pearson's-r coefficient for two linearly dependent variables. Add some noise and see the effect of varying the noise. \n",
    "2. Simulate and visualize some data with positive linear correlation\n",
    "3. Simulate and visualize some data with negative linear correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.arange(-5, 5, 0.1)\n",
    "pp = 1.5  # level of noise\n",
    "yy = xx + np.random.normal(0, pp, size=len(xx))\n",
    "\n",
    "# visualize the data\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xx, yy, c='r', edgecolor='none')\n",
    "ax.set_xlabel('X data')\n",
    "ax.set_ylabel('Y data')\n",
    "\n",
    "line_coef = np.polyfit(xx, yy, 1)\n",
    "line_xx = np.arange(-5, 5, 0.1)\n",
    "line_yy = line_coef[0]*line_xx + line_coef[1]\n",
    "\n",
    "ax.plot(line_xx, line_yy, 'b', lw=2)\n",
    "\n",
    "print scipy.stats.pearsonr(xx, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's r coefficient is limited to analyze the linear correlation between two variables. It is not capable to show the non-linear dependency. Investigate the Pearson's r coefficient between two variables that are correlated non-linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some data, first for X\n",
    "xx = np.arange(-5, 5, 0.1)\n",
    "\n",
    "# assume Y = 2Y + some perturbation\n",
    "pp = 1.1  # level of noise\n",
    "yy = xx**2 + np.random.normal(0, pp, size=len(xx))\n",
    "\n",
    "# visualize the data\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xx, yy, c='r', edgecolor='b')\n",
    "ax.set_xlabel('X data')\n",
    "ax.set_ylabel('Y data')\n",
    "ax.set_title('$Y = X^2+\\epsilon$', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pearson's-r correlation is near zero which means there is no linear correlation. But how about non-linear correlation? Isn't $y=x^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(xx,yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"spearman\"></a>\n",
    "\n",
    "\n",
    "### <span style=\"color:#0b486b\">1.2 Spearman's rank coefficient</span>\n",
    "\n",
    "Spearman's rank coefficient is used for discrete/ordinal data. Find the Spearman's rank between horse power and number of cylinders of the car data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#horse = np.array([float(dd[4]) for dd in data[1:]])\n",
    "#cylinder = np.array([float(dd[2]) for dd in data[1:]])\n",
    "horse = data['Horse power']\n",
    "cylinder = data['cylinder number']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5), dpi=100)\n",
    "ax.scatter(horse, cylinder, alpha=0.6, edgecolor='none', s=100)\n",
    "ax.set_xlabel('Horse power')\n",
    "ax.set_ylabel('#Cylinders')\n",
    "\n",
    "print (scipy.stats.spearmanr(horse, cylinder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**. \n",
    "Compute the spearman rank correlation between \"Horse power\" and \"Engine displacement\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#0b486b\">2. Linear Regression</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we investigate a simple case by fitting a linear regression for three data points. First we simulate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating the data\n",
    "\n",
    "x = np.c_[0, 1, 2, 1.5].T\n",
    "y  = [1, 1.5, 3.1, 1.5]\n",
    "\n",
    "print (\"x:\",x)\n",
    "print (\"y:\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=100)\n",
    "ax.scatter(x, y, c='r')\n",
    "ax.set_title('simulated data')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# instanciate the model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Coefficients:\", lr.coef_)\n",
    "print (\"   Intercept:\", lr.intercept_)\n",
    "# print (\"    Residues:\", lr.residues_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the line to see how it estimates our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lr.predict(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=100)\n",
    "ax.scatter(x, y, c='r')\n",
    "ax.plot(x, yhat)\n",
    "\n",
    "ax.set_title('simulated data and the estimated line')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method `predict()` to predict `y` for a new `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.c_[4, 2.3].T\n",
    "y_test = lr.predict(x_test)\n",
    "\n",
    "print (\"x_test.T:\", x_test.T)\n",
    "print (\"y_test:\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"mlr\"></a>\n",
    "\n",
    "\n",
    "### <span style=\"color:#0b486b\">2.1 Multiple Linear Regression</span>\n",
    "\n",
    "\n",
    "Multiple linear regression attempts to model the relationship between two or more explanatory variables and a response variable by fitting a linear equation to observed data. Every value of the independent variable x is associated with a value of the dependent variable y. For example if we have two explanatory variables (attributes, features), our data has such a form:\n",
    "\n",
    "$$\n",
    "D=\\left\\{ \\left(\\left(x_{1,1},x_{2,1}\\right),y_{1}\\right),\\left(\\left(x_{1,2},x_{2,2}\\right),y_{2}\\right),\\ldots,\\left(\\left(x_{1,n},x_{2,n}\\right),y_{n}\\right)\\right\\} \n",
    "$$\n",
    "\n",
    "Now we fit a multiple linear regression $y = x_1 + 2x_2 + 1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the data\n",
    "\n",
    "x = np.c_[[0, 0], [0, 1], [1, 1], [1, 0]].T\n",
    "y = [1.5, 3.2, 4, 2]\n",
    "\n",
    "print (x)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = linear_model.LinearRegression(fit_intercept=True)\n",
    "mlr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"mlr.coef_:\", mlr.coef_)\n",
    "print (\"mlr.intercept_:\", mlr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"mlr.predict(x):\", mlr.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises 3**: \n",
    "\n",
    "As the score suggests, now we have the perfect regression. Change the values of $y$ slightly and see what effect it has on the `mlr`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"rmhp\"></a>\n",
    "\n",
    "\n",
    "### <span style=\"color:#0b486b\">2.2 Regression for median house prices</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the package `pandas` for reading and storing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to use wget if you've retrieved file from clouddeakin.\n",
    "wget.download('https://raw.githubusercontent.com/gaoshangdeakin/SIT384/master/housing_300.csv')\n",
    "\n",
    "data = pd.read_csv('housing_300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the scatter plot of the number of rooms vs the median house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7), dpi=100)\n",
    "median_prices = data['MEDV']\n",
    "avg_rooms = data['RM']\n",
    "scales = 50*np.ones(len(median_prices))\n",
    "ax.scatter(avg_rooms, median_prices, color='b',s=scales, alpha=0.7, edgecolor='r')\n",
    "plt.xlabel('$X$ (number of rooms)')\n",
    "plt.ylabel('$Y$ (median house prices)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"avg_rooms.shape:\", avg_rooms.shape)\n",
    "print (\"median_prices.shape:\", median_prices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How correlated are the number of rooms and the price of the house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(avg_rooms, median_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to fit a linear regression mode on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "x = np.c_[avg_rooms.values]\n",
    "y = median_prices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (lr.coef_)\n",
    "print (lr.intercept_)\n",
    "# print lr.residues_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the model parameters\n",
    "\n",
    "print (lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "\n",
    "yhat = lr.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"x[:10]:\", x[:10])\n",
    "print (\"yhat[:10]:\", yhat[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the result\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(7,7),dpi=100)\n",
    "\n",
    "scales = 20*np.ones(len(median_prices))\n",
    "ax.scatter(avg_rooms,median_prices,color='b',s=scales,alpha=0.7,edgecolor='r')\n",
    "plt.xlabel('$X$ (number of rooms)')\n",
    "plt.ylabel('$Y$ (median house prices)')\n",
    "\n",
    "# plot the regression linear leared\n",
    "ax.plot(x,yhat)\n",
    "\n",
    "# visualize the residuals\n",
    "tmp = np.reshape(x,[1,len(x)])[0]\n",
    "tmp_x = []\n",
    "tmp_y = []\n",
    "for i in range(len(x)):\n",
    "    tmp_x = np.append(tmp_x,tmp[i])\n",
    "    tmp_y = np.append(tmp_y,y[i])\n",
    "    tmp_x = np.append(tmp_x,tmp[i])\n",
    "    tmp_y = np.append(tmp_y,yhat[i])\n",
    "    ax.plot(tmp_x,tmp_y,color='g',linewidth=0.5)\n",
    "    tmp_x = []\n",
    "    tmp_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum of residual\n",
    "# lr.residues_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is customary to test your model on **unseen** data. So we divide our data into two parts. We use 70% of it to train the model and 30% to evaluate its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.7\n",
    "split_idx = int(np.round(split * len(data)))\n",
    "split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0:200]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True)\n",
    "train_data.plot(kind='scatter', x='RM', y='MEDV', ax=axs[0], figsize=(7, 7))\n",
    "train_data.plot(kind='scatter', x='AGE', y='MEDV', ax=axs[1], figsize=(7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[200:300]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_data['RM'].values\n",
    "train_X = np.c_[train_X]\n",
    "train_Y = train_data['MEDV'].tolist()\n",
    "\n",
    "test_X = test_data['RM'].values\n",
    "test_X = np.c_[test_X]\n",
    "test_Y = test_data['MEDV'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(train_X))\n",
    "print (train_X.shape)\n",
    "print (type(train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build a linear regression model from training data\n",
    "'''\n",
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (lr.coef_)\n",
    "print (lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the linear regression result and the data to see how it fits the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(7,7),dpi=100)\n",
    "\n",
    "# plot training data\n",
    "scales = 20*np.ones(len(train_Y))\n",
    "ax.scatter(train_X,train_Y,color='b',s=scales,alpha=0.7,edgecolor='r')\n",
    "plt.xlabel('$X$ (number of rooms)')\n",
    "plt.ylabel('$Y$ (median house prices)')\n",
    "plt.title('Training a simple linear regression model')\n",
    "\n",
    "# plot the regression line\n",
    "train_Yhat = lr.predict(train_X)\n",
    "plt.plot(train_X,train_Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained the model parameters, we can use the model to predict for unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = lr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(7,7),dpi=100)\n",
    "\n",
    "# plot the predicted points along the prediction line\n",
    "scales = 30*np.ones(len(test_X))\n",
    "ax.scatter(test_X,yhat_test,s=scales,color='b',edgecolor='r')\n",
    "ax.plot(test_X,yhat_test,color='b',linewidth=.2)\n",
    "\n",
    "# plot the true values\n",
    "scales = 30*np.ones(len(test_X))\n",
    "ax.scatter(test_X,test_Y,s=scales,color='g',edgecolor='b')\n",
    "\n",
    "# plot the residual line\n",
    "tmp = np.reshape(test_X,[1,len(test_X)])[0]\n",
    "tmp_x = []\n",
    "tmp_y = []\n",
    "for i in xrange(len(test_X)):\n",
    "    tmp_x = np.append(tmp_x,tmp[i])\n",
    "    tmp_y = np.append(tmp_y,yhat_test[i])\n",
    "    tmp_x = np.append(tmp_x,tmp[i])\n",
    "    tmp_y = np.append(tmp_y,test_Y[i])\n",
    "    ax.plot(tmp_x,tmp_y,color='red',linewidth=0.5)\n",
    "    tmp_x = []\n",
    "    tmp_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#0b486b\">3. Distances</span>\n",
    "\n",
    "`Distance` is a numerical description of how far apart objects are. It is a concrete way of describing what it means for elements of some space to be close or far away from each other, for example the distance between two vectors in an 2-dimensional space.\n",
    "\n",
    "Now that you have know how to represent an n-dimensional vector in Python with NumPy arrays, we will write a function as a metric to measure the distance between two vectors. There are multiple ways to measure the distance between two vectors. We will discuss Euclidean distance and cosine distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id = \"euclidean\"></a>\n",
    "\n",
    "\n",
    "### <span style=\"color:#0b486b\">3.1 Euclidean Distance</span>\n",
    "\n",
    "Euclidean distance comes from Geometry. If we assume $\\mathbf{x}_{1}=\\left[x_{11},x_{12},\\ldots,x_{1n}\\right]$ and $\\mathbf{x}_{2}=\\left[x_{21},x_{22},\\ldots,x_{2n}\\right]$, then the Euclidean distance between $\\mathbf{x}_{1}$ and $\\mathbf{x}_{2}$ is defined as:\n",
    "\n",
    "$$d\\left(\\mathbf{x}_{1},\\mathbf{x}_{2}\\right)=\\sqrt{\\left(x_{11}-x_{21}\\right)^{2}+\\left(x_{12}-x_{22}\\right)^{2}+\\ldots+\\left(x_{1n}-x_{2n}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "We can use array operators for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([2, 5, 4, 6, 8])\n",
    "x2 = np.array([3, 5, 6, 8, 6])\n",
    "\n",
    "print (x1 - x2)\n",
    "print ((x1 - x2) ** 2)\n",
    "print (np.sqrt(np.sum((x1 - x2) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance1(x1, x2):\n",
    "    d = x1 - x2\n",
    "    d = d ** 2\n",
    "    return np.sqrt(d.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([-1, 2, 0, 5])\n",
    "x2 = np.array([4, 2, 1, 0])\n",
    "\n",
    "print (euclidean_distance1(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since two vectors passed to the function should be the same size, it is better to perform a sanity check before applying the subtraction. Otherwise it will raise an error. We can do this by using `if - elif` statement or as a better practice by using `try - except`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def euclidean_distance2(x1, x2):\n",
    "    if x1.shape[0] != x2.shape[0]:\n",
    "        sys.exit('x1 and x2 are not the same size')\n",
    "    else:\n",
    "        d = x1 - x2\n",
    "        d = d ** 2\n",
    "        return np.sqrt(d.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this cell\n",
    "\n",
    "x1 = np.array([-1, 2, 0, 5, 9])\n",
    "x2 = np.array([4, 2, 1, 0, 1])\n",
    "euclidean_distance2(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance3(x1, x2):\n",
    "    try:\n",
    "        d = x1 - x2\n",
    "        d = np.power(d, 2)\n",
    "        return np.sqrt(d.sum())\n",
    "    except ValueError as e:\n",
    "        print (\"Vectors passed to the function are not the same size\")\n",
    "        # you can return a default value\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix this cell\n",
    "\n",
    "x1 = np.array([-1, 2, 0, 5, 9])\n",
    "x2 = np.array([4, 2, 1, 2])\n",
    "a = euclidean_distance3(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance4(x1, x2):\n",
    "    try:\n",
    "        d = np.array(x1) - np.array(x2)\n",
    "        d = np.power(d, 2)\n",
    "        return np.sqrt(d.sum())\n",
    "    except ValueError as e:\n",
    "        print (\"Vectors passed to the function are not the same size\")\n",
    "        # you can return a default value\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"cosine\"></a>\n",
    "\n",
    "### <span style=\"color:#0b486b\">3.2 cosine similarity and distance</span>\n",
    "\n",
    "Cosine similarity is a measure of similarity between two vectors based on the angle between them. Cosine similarity is widely used in information retrieval and text mining as a measure of similarity between documents and is defined as:\n",
    "\n",
    "$$S_{c}\\left(\\mathbf{x}_{1},\\mathbf{x_{2}}\\right)=\\frac{\\mathbf{x}_{1}.\\mathbf{x_{2}}}{\\parallel\\mathbf{x}_{1}\\parallel^{2}+\\parallel\\mathbf{x}_{2}\\parallel^{2}-\\mathbf{x}_{1}.\\mathbf{x_{2}}}$$\n",
    "\n",
    "\n",
    "Cosine similarity is particularly used in positive space where the outcome is bounded in [0, 1]. The cosine distance is defined as the complement to cosine similarity in positive space that is $D_{c}\\left(x_{1},x_{2}\\right)=1-S_{c}\\left(x_1,x_2\\right)$ where $D_c$ is the cosine distance and $S_c$ is the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([3,4,6])\n",
    "\n",
    "print(x1 * x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x1, x2):\n",
    "    try:\n",
    "        num = (x1*x2).sum()\n",
    "        denom = (x1*x1).sum() + (x2*x2).sum() - (x1*x2).sum()\n",
    "        num += 0.0    # or use np.astype(float) to make sure of float division\n",
    "        return 1 - num/denom\n",
    "    except ValueError as e:\n",
    "        print (\"Vectors passed to the function are not the same size\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([2, 0, 5, 9])\n",
    "x2 = np.array([4, 2, 1, 0])\n",
    "cosine_distance(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tasks</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the provided examples and get yourself familiar with sample plot code before attempting portolio tasks.\n",
    "\n",
    "Please show your attempt to your tutor before you leave the lab, or email your files to your coordinator if you are an off-campus student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Summary</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we have covered: \n",
    " - data dependency, linear regression and distances.\n",
    " - how to apply linear regression in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "1. Yash Soni, \"Machine Learning for dummies — explained in 3 mins!\", https://becominghuman.ai/machine-learning-for-dummies-explained-in-2-mins-e83fbc55ac6d, accessed 31/03/2019."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
